{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob, random, time, os, zlib\n",
    "import model\n",
    "\n",
    "FEATURE_COUNT = 6 + 6 + 1\n",
    "CROSS_VAL_SIZE = 3000\n",
    "IN_SAMPLE_SIZE = 1000\n",
    "MINIBATCH_SIZE = 256\n",
    "DATA_ROOT = \"build2/\"\n",
    "TOTAL_CHUNK_COUNT = 12\n",
    "\n",
    "def to_hms(x):\n",
    "    x = int(x)\n",
    "    seconds = x % 60\n",
    "    minutes = (x // 60) % 60\n",
    "    hours   = x // 60 // 60\n",
    "    return \"%2i:%02i:%02i\" % (hours, minutes, seconds)\n",
    "\n",
    "# For some reason some Python versions basically explode on .decode(\"zlib\") for large strings.\n",
    "# We can bypass by just decoding it in blocks ourself and assembling them.\n",
    "def stream_decompress(s):\n",
    "    decomp = zlib.decompressobj()\n",
    "    block_size = 2**23\n",
    "    i = 0\n",
    "    results = []\n",
    "    while i < len(s):\n",
    "        block = s[i:i+block_size]\n",
    "        results.append(decomp.decompress(block))\n",
    "        i += block_size\n",
    "    results.append(decomp.flush())\n",
    "    return \"\".join(results)\n",
    "\n",
    "def load_chunk(features, moves):\n",
    "    def load_flat_array(path, shape):\n",
    "        with open(path) as f:\n",
    "            data = f.read()\n",
    "        data = stream_decompress(data)\n",
    "        return np.fromstring(data, dtype=np.int8).reshape(shape)\n",
    "    features = load_flat_array(features, (-1, 8, 8, FEATURE_COUNT))\n",
    "    moves    = load_flat_array(moves, (-1, 8, 8, 2))\n",
    "    # Move each sample to be of shape (2, 8, 8) so we can use tf.nn.softmax_cross_entropy_with_logits_v2.\n",
    "    moves    = np.moveaxis(moves, -1, 1)\n",
    "    assert len(features) == len(moves)\n",
    "    return {\"features\": features, \"moves\": moves}\n",
    "\n",
    "# Views into the extremely large dataset.\n",
    "next_chunk_index = 0\n",
    "chunk = None\n",
    "in_sample_test = None\n",
    "\n",
    "def load_next_chunk():\n",
    "    global next_chunk_index, chunk, in_sample_test\n",
    "    print \"    >>> Loading chunk:\", next_chunk_index\n",
    "    # Free the memory from the previous chunk FIRST, if we have one loaded.\n",
    "    # This is necessary to avoid running out of memory.\n",
    "    if chunk is not None:\n",
    "        del chunk\n",
    "        del in_sample_test\n",
    "    start = time.time()\n",
    "    chunk = load_chunk(\n",
    "        os.path.join(DATA_ROOT, \"features_%03i.z\" % next_chunk_index),\n",
    "        os.path.join(DATA_ROOT, \"moves_%03i.z\" % next_chunk_index),\n",
    "    )\n",
    "    next_chunk_index = (next_chunk_index + 1) % TOTAL_CHUNK_COUNT\n",
    "    in_sample_test = {\n",
    "        \"features\": chunk[\"features\"][:IN_SAMPLE_SIZE],\n",
    "        \"moves\":    chunk[\"moves\"][:IN_SAMPLE_SIZE],\n",
    "    }\n",
    "    stop = time.time()\n",
    "    print \"    >>> (In %f) Samples: %i\" % (stop - start, len(chunk[\"features\"]))\n",
    "\n",
    "def get_random_subset(samples, n):\n",
    "    indices = random.sample(xrange(len(samples[\"features\"])), n)\n",
    "    return {\n",
    "        \"features\": [samples[\"features\"][i] for i in indices],\n",
    "        \"moves\": [samples[\"moves\"][i] for i in indices],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    >>> Loading chunk: 0\n",
      "    >>> (In 9.556681) Samples: 6764463\n"
     ]
    }
   ],
   "source": [
    "load_next_chunk()\n",
    "cross_val = load_chunk(\n",
    "    os.path.join(DATA_ROOT, \"test_features.z\"),\n",
    "    os.path.join(DATA_ROOT, \"test_moves.z\"),\n",
    ")\n",
    "cross_val = get_random_subset(cross_val, CROSS_VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total network parameters: 5913474\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "net = model.ChessNet()\n",
    "print \"Total network parameters:\", net.total_parameters\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "total_training_steps = 0\n",
    "loss_plot = []\n",
    "in_sample_loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_counter = 0\n",
    "def save_model():\n",
    "    global model_save_counter\n",
    "    model_save_counter += 1\n",
    "    model.sess = sess\n",
    "    model.save_model(net, \"model-%03i.npy\" % model_save_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m211094 [ 0:00:00 -  0:00:00] Loss: 1.796184  In-sample loss: 1.955742  Accuracy: 28.933  lr = 0.001606\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_work = 0.0\n",
    "start_time = time.time()\n",
    "best_loss = float(\"inf\")\n",
    "lr_schedule = lambda step: 0.01 * 0.5**(step / 8e4)\n",
    "\n",
    "for overall_step in range(10000):\n",
    "    lr = lr_schedule(total_training_steps)\n",
    "    elapsed = time.time() - start_time\n",
    "    in_sample_loss = net.get_loss(in_sample_test)\n",
    "    loss = net.get_loss(cross_val)\n",
    "    color_pair = \"\", \"\"\n",
    "    if loss < best_loss:\n",
    "        color_pair = \"\\x1b[31m\", \"\\x1b[0m\"\n",
    "    message = \"%s%6i [%s - %s] Loss: %.6f  In-sample loss: %.6f  Accuracy: %.3f  lr = %f%s\" % (\n",
    "        color_pair[0],\n",
    "        total_training_steps,\n",
    "        to_hms(elapsed),\n",
    "        to_hms(total_work),\n",
    "        loss,\n",
    "        in_sample_loss,\n",
    "        net.get_accuracy(cross_val) * 100,\n",
    "        lr,\n",
    "        color_pair[1]\n",
    "    )\n",
    "    print(message)\n",
    "    with open(\"/home/snp/chess_training_log\", \"a+\") as f:\n",
    "        print >>f, message\n",
    "    loss_plot.append((total_training_steps, loss))\n",
    "    in_sample_loss_plot.append((total_training_steps, in_sample_loss))\n",
    "    best_loss = min(best_loss, loss)\n",
    "\n",
    "    for _ in range(500):\n",
    "        minibatch = get_random_subset(chunk, MINIBATCH_SIZE)\n",
    "        working = time.time()\n",
    "        net.train(minibatch, lr)\n",
    "        total_work += time.time() - working\n",
    "        # Try really hard to not keep any views around!\n",
    "        del minibatch\n",
    "        total_training_steps += 1\n",
    "\n",
    "    # Periodically swap out the data for fresh training data.\n",
    "    if (overall_step + 1) % 5 == 0:\n",
    "        load_next_chunk()\n",
    "    if (overall_step + 1) % 50 == 0:\n",
    "        save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess = sess\n",
    "model.save_model(net, \"model.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hold(True)\n",
    "plt.plot(*zip(*loss_plot[6:]))\n",
    "plt.plot(*zip(*in_sample_loss_plot[6:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
